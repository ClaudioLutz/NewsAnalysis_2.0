# Story 011.5: Migrate filter.py Using Hybrid Pattern

**Story ID:** 011.5  
**Epic:** 011 - Hybrid Prompt Architecture Migration  
**Created:** 2025-10-05  
**Status:** Blocked by 011.4  
**Priority:** High  
**Effort:** 2 days  
**Confidence:** 85%

---

## Story

As a developer, I need filter.py migrated to use the fragment-based hybrid architecture so that classification prompts are centralized while still supporting dynamic runtime data.

---

## Context

Filter.py is the critical blocker that stopped Story 011.3. It builds prompts dynamically with:
- Topic-specific keywords (from config)
- Focus areas (from config)
- Creditreform business context

The hybrid architecture established in Story 011.4 provides the pattern to handle this:
- Static prompt structure → fragments.yaml
- Dynamic runtime data → Python composition
- Clear separation of concerns

---

## Acceptance Criteria

- [ ] Static prompt fragments extracted to `config/prompts/fragments.yaml`
- [ ] `classify_article()` refactored to use fragment composition
- [ ] `build_creditreform_system_prompt()` refactored to use fragment composition
- [ ] Dynamic context building methods implemented
- [ ] Baseline validation passes (same classification decisions)
- [ ] Tests updated
- [ ] Code is cleaner and more maintainable

---

## Tasks

### Task 1: Extract Static Fragments
**Subtasks:**
- [ ] Identify all static text in filter.py prompts
- [ ] Add to `config/prompts/fragments.yaml` under `filter` category:
  - [ ] `classifier_intro` - Opening context about being a Swiss news classifier
  - [ ] `classification_criteria` - The "Classify based on:" section
  - [ ] `creditreform_context` - Creditreform business description
  - [ ] `focus_areas_header` - "KEY FOCUS AREAS:" text
  - [ ] `relevance_scale` - High/Medium/Low relevance descriptions
- [ ] Validate YAML syntax

**Example Fragment Structure:**
```yaml
filter:
  classifier_intro: |
    You are an expert news classifier for Swiss business and financial news.
    Your task is to determine if an article is relevant to the topic: {topic}
  
  classification_criteria: |
    Classify based on:
    1. Title content and keywords
    2. URL structure and domain
    3. Relevance to Swiss business/financial context
  
  creditreform_context: |
    CREDITREFORM CONTEXT:
    {description}
    
    You're filtering news for a Product Manager/Data Analyst at Creditreform Switzerland.
  
  focus_areas_header: "KEY FOCUS AREAS:"
  
  relevance_scale: |
    - HIGH RELEVANCE (0.85+): Direct impact on credit risk business
    - MEDIUM RELEVANCE (0.70-0.84): Industry trends, general business climate
    - LOW RELEVANCE (< 0.70): Tangential business news, consumer finance
```

### Task 2: Refactor classify_article() Method
**Subtasks:**
- [ ] Create `_build_classification_prompt()` helper method
- [ ] Use `get_fragment()` to retrieve static parts
- [ ] Build dynamic context (keywords, focus areas) in Python
- [ ] Use `.format()` to compose final prompt
- [ ] Test with multiple topics
- [ ] Verify confidence scores match baseline

**Implementation Pattern:**
```python
def _build_classification_prompt(self, topic: str, keywords: List[str], 
                                focus_areas: Dict) -> str:
    """Build classification prompt using fragments + dynamic data."""
    
    # Get static fragments
    intro = self.prompt_lib.get_fragment('filter', 'classifier_intro')
    criteria = self.prompt_lib.get_fragment('filter', 'classification_criteria')
    output_format = self.prompt_lib.get_fragment('common', 'output_format')
    
    # Build dynamic context
    keywords_text = ', '.join(keywords)
    focus_text = self._format_focus_areas(focus_areas)
    
    # Compose final prompt
    return f"""{intro.format(topic=topic)}

Topic keywords: {keywords_text}

{focus_text}

{criteria}

{output_format}"""

def classify_article(self, title: str, url: str, topic: str) -> Dict[str, Any]:
    """Classify article using fragment-based prompt."""
    topic_config = self.topics_config['topics'].get(topic, {})
    keywords = topic_config.get('include', [])
    
    # Build system prompt using fragments
    system_prompt = self._build_classification_prompt(
        topic=topic,
        keywords=keywords,
        focus_areas=topic_config.get('focus_areas', {})
    )
    
    # Rest of classification logic unchanged
    ...
```

### Task 3: Refactor build_creditreform_system_prompt() Method
**Subtasks:**
- [ ] Use `get_fragment('filter', 'creditreform_context')`
- [ ] Build focus areas text dynamically
- [ ] Use `get_fragment('filter', 'relevance_scale')`
- [ ] Compose final prompt with `.format()`
- [ ] Test with Creditreform topic config

**Implementation Pattern:**
```python
def build_creditreform_system_prompt(self, topic_config: Dict[str, Any]) -> str:
    """Build enhanced prompt for Creditreform context using fragments."""
    
    # Get static fragments
    context_template = self.prompt_lib.get_fragment('filter', 'creditreform_context')
    focus_header = self.prompt_lib.get_fragment('filter', 'focus_areas_header')
    relevance_scale = self.prompt_lib.get_fragment('filter', 'relevance_scale')
    output_format = self.prompt_lib.get_fragment('common', 'output_format')
    
    # Build dynamic parts
    description = topic_config.get('description', '')
    focus_areas = topic_config.get('focus_areas', {})
    focus_text = self._build_focus_areas_text(focus_areas)
    
    # Compose final prompt
    return f"""{context_template.format(description=description)}

{focus_header}
{focus_text}

{relevance_scale}

{output_format}"""
```

### Task 4: Implement Dynamic Context Builders
**Subtasks:**
- [ ] Refactor or create `_format_focus_areas()` method
- [ ] Create `_build_focus_areas_text()` if needed
- [ ] Ensure defensive checks for None values
- [ ] Add type hints
- [ ] Document expected input format

**Helper Method Example:**
```python
def _format_focus_areas(self, focus_areas: Dict[str, Any]) -> str:
    """Format focus areas dictionary into display text.
    
    Args:
        focus_areas: Dict mapping area names to config
        
    Returns:
        Formatted text for prompt insertion
    """
    if not focus_areas:
        return ""
    
    focus_text = ""
    for area, info in focus_areas.items():
        if info and isinstance(info, dict):
            keywords = info.get('keywords', [])
            priority = info.get('priority', 'medium')
            if keywords:
                focus_text += f"\n- {area} ({priority} priority): {', '.join(keywords)}"
    
    return focus_text
```

### Task 5: Update Tests
**Subtasks:**
- [ ] Add test for `_build_classification_prompt()`
- [ ] Add test for fragment composition
- [ ] Add test for dynamic context building
- [ ] Update existing filter tests if needed
- [ ] Add edge case tests (empty keywords, None focus_areas)

**Test Template:**
```python
def test_classification_prompt_composition():
    """Test that prompt is built correctly from fragments."""
    filter_instance = AIFilter('test.db', 'topics.yaml')
    
    prompt = filter_instance._build_classification_prompt(
        topic='test_topic',
        keywords=['keyword1', 'keyword2'],
        focus_areas={'area1': {'keywords': ['k1'], 'priority': 'high'}}
    )
    
    assert 'test_topic' in prompt
    assert 'keyword1' in prompt
    assert 'area1' in prompt
    assert 'high priority' in prompt
```

### Task 6: Baseline Validation
**Subtasks:**
- [ ] Run filter stage with migrated code
- [ ] Compare classification results to baseline
- [ ] Verify same articles matched with same confidence
- [ ] Check for any behavior differences
- [ ] Document validation results
- [ ] Update migration_progress.md

**Validation Checklist:**
- [ ] Same number of articles classified
- [ ] Same articles marked as matches
- [ ] Confidence scores within 0.01 tolerance
- [ ] No new errors or warnings
- [ ] Performance similar (no major slowdown)

---

## Dev Notes

### Files to Modify
1. **news_pipeline/filter.py** - Main refactoring
2. **config/prompts/fragments.yaml** - Add filter fragments
3. **tests/test_filter.py** - Update/add tests (if exists)

### Key Methods to Refactor
- `classify_article()` - Uses generic classification prompt
- `build_creditreform_system_prompt()` - Uses enhanced Creditreform prompt
- `classify_article_enhanced()` - Similar to classify_article

### Baseline Files for Validation
- `baseline.db` - Classification results
- `baseline_output.md` - Pipeline output
- Use these to verify no behavior changes

### Dynamic Data Sources
- Keywords: `topic_config.get('include', [])`
- Focus areas: `topic_config.get('focus_areas', {})`
- Topic description: `topic_config.get('description', '')`
- Thresholds: `topic_config.get('confidence_threshold', 0.70)`

---

## Definition of Done

- [ ] All tasks completed
- [ ] All subtasks checked off
- [ ] Static fragments extracted to YAML
- [ ] Dynamic composition implemented in Python
- [ ] All tests passing
- [ ] Baseline validation confirms same behavior
- [ ] Code reviewed
- [ ] Documentation updated
- [ ] No warnings or errors
- [ ] Pattern consistent with Story 011.4

---

## References

- **Epic:** `docs/stories/epic-011-hybrid-prompt-migration.md`
- **Previous:** `docs/stories/011.4.establish-fragment-architecture.md`
- **Analysis:** `docs/stories/011.3-elicitation-findings.md` (see filter.py section)
- **Blocked Story:** `docs/stories/011.3.big-bang-migration.md` (this unblocks it)

---

## Risk Mitigation

**Risk:** Validation fails (different classification results)  
**Mitigation:** 
- Compare prompts character-by-character before/after
- Test with small sample first
- Have rollback plan ready

**Risk:** Fragment composition more complex than expected  
**Fallback:** Simplify to basic format strings without fragments

**Risk:** Performance degradation  
**Mitigation:** Cache fragments, profile if needed

---

**Story Created:** 2025-10-05  
**Created By:** Bob (Scrum Master) 🏃  
**Blocked By:** Story 011.4  
**Unblocks:** Story 011.6
