# Story 011.1: Create PromptLibrary Architecture & Core Implementation

## Status
Ready for Review

## Story
**As a** Developer implementing prompt centralization,
**I want** to create the core PromptLibrary architecture with pipeline stage organization,
**so that** we have a solid foundation for centralizing scattered prompts and can begin migrating prompts from individual files.

## Acceptance Criteria

1. `news_pipeline/prompt_library.py` created with main PromptLibrary class
2. Stage-specific subclasses implemented (FilteringPrompts, DeduplicationPrompts, AnalysisPrompts, FormattingPrompts, DigestPrompts)
3. YAML loading mechanism implemented with caching for performance
4. Language integration with LanguageConfig completed via dependency injection
5. Example prompt validates architecture works end-to-end
6. Documentation in docstrings with usage examples
7. Unit tests for PromptLibrary core functionality pass

## Tasks / Subtasks

- [x] Task 1: Create PromptLibrary base infrastructure (AC: 1, 3)
  - [x] Create `news_pipeline/prompt_library.py` file
  - [x] Implement `PromptLibrary` main class with YAML loading
  - [x] Add caching mechanism to avoid repeated file reads
  - [x] Implement error handling for missing YAML files
  - [x] Add logging using existing `utils.py` patterns

- [x] Task 2: Implement pipeline stage subclasses (AC: 2)
  - [x] Create `FilteringPrompts` subclass for filtering stage
  - [x] Create `DeduplicationPrompts` subclass for deduplication stage
  - [x] Create `AnalysisPrompts` subclass for analysis stage
  - [x] Create `FormattingPrompts` subclass for formatting stage
  - [x] Create `DigestPrompts` subclass for digest generation stage
  - [x] Each subclass exposes methods for accessing stage-specific prompts

- [x] Task 3: Implement language integration (AC: 4)
  - [x] Accept `LanguageConfig` instance in PromptLibrary constructor
  - [x] Implement language-aware prompt retrieval
  - [x] Support both German and English language selection
  - [x] Follow existing patterns from `language_config.py`

- [x] Task 4: Create example validation (AC: 5)
  - [x] Create minimal example YAML file for testing
  - [x] Implement end-to-end example showing:
    * YAML file loading
    * Prompt retrieval with parameters
    * Language selection
  - [x] Validate architecture design with working example

- [x] Task 5: Add comprehensive documentation (AC: 6)
  - [x] Add module-level docstring explaining PromptLibrary purpose
  - [x] Document all classes with Google-style docstrings
  - [x] Include usage examples in docstrings
  - [x] Document parameter substitution approach
  - [x] Add examples for each pipeline stage

- [x] Task 6: Create unit tests (AC: 7)
  - [x] Test YAML loading with valid files
  - [x] Test caching mechanism works correctly
  - [x] Test error handling for missing files
  - [x] Test parameter substitution
  - [x] Test language integration
  - [x] Test each pipeline stage subclass
  - [x] All tests pass

## Dev Notes

### Context from Epic 011

**Source Document:** docs/stories/epic-prompt-library-011-centralization.md

**Background:**
This story creates the foundational infrastructure for centralizing GPT-5 system prompts that are currently scattered across 7 files in the codebase. The core problem is **discoverability** - prompts are hard to find because they're embedded in Python code.

**Current State:**
- Prompts scattered in: `summarizer.py`, `gpt_deduplication.py`, `german_rating_formatter.py`, `filter.py`, `cross_run_deduplication.py`, `incremental_digest.py`, `analyzer.py`
- Partial centralization exists in `language_config.py` (~40%) but mixes concerns (language switching + prompt management)
- Duplication exists: `german_rating_formatter.py` duplicates prompts from `language_config.py`

**Goal:**
Create separate PromptLibrary class focused solely on prompt management, with language switching handled by injecting LanguageConfig.

### Architecture Design

**Source:** docs/brainstorming-session-results.md

**Key Design Decisions:**

1. **Pipeline Stage Organization:**
   - Organize prompts by pipeline stage (filtering, deduplication, analysis, formatting, digest)
   - Matches developer mental model of the codebase structure
   - Makes prompts intuitive to find: "I need a filtering prompt" → FilteringPrompts

2. **Method-Based Access:**
   ```python
   # Initialize with language config
   prompt_lib = PromptLibrary(language_config)
   
   # Access via pipeline stage methods
   prompt = prompt_lib.filtering.classification_prompt(topic="creditreform")
   prompt = prompt_lib.deduplication.clustering_prompt()
   prompt = prompt_lib.formatting.rating_prompt()
   ```

3. **YAML Storage Format:**
   - Configuration in `config/prompts/` directory
   - One YAML file per pipeline stage
   - Simple Python string templates using `{variable}` syntax
   - Rich metadata (description, parameters, examples, cost estimates)

4. **Language Integration:**
   - Accept LanguageConfig via constructor (dependency injection)
   - PromptLibrary returns language-appropriate prompts
   - Separates concerns: PromptLibrary = prompts, LanguageConfig = language switching

**Example YAML Structure:**
```yaml
classification_prompt:
  description: "Classifies articles by topic relevance"
  purpose: "Initial filtering to identify creditreform-related articles"
  parameters:
    - name: topic
      required: true
      description: "Topic to filter by (e.g., 'creditreform')"
  template: |
    Classify the following article...
    Topic: {topic}
  cost_estimate: "~500 tokens per call"
  example_usage: |
    prompt = prompt_lib.filtering.classification_prompt(topic="creditreform")
```

### Project Structure Context

**Source:** docs/architecture.md

**New File Location:**
```
news_pipeline/
├── prompt_library.py          # NEW: Core PromptLibrary infrastructure
├── language_config.py         # EXISTING: Will be refactored in Story 3
├── analyzer.py                # EXISTING: Uses prompts (will migrate in Story 3)
├── filter.py                  # EXISTING: Uses prompts (will migrate in Story 3)
└── ...
```

**Config Directory:**
```
config/
├── prompts/                   # NEW: YAML files created in Story 2
│   ├── filtering.yaml         # Story 2
│   ├── deduplication.yaml     # Story 2
│   ├── analysis.yaml          # Story 2
│   ├── formatting.yaml        # Story 2
│   └── digest.yaml            # Story 2
├── feeds.yaml                 # EXISTING
└── topics.yaml                # EXISTING
```

### Implementation Patterns to Follow

**Source:** docs/architecture.md - Coding Standards

**Follow Existing Patterns:**

1. **Type Hints (from gpt_deduplication.py):**
```python
from typing import Dict, List, Optional, Any

class PromptLibrary:
    def __init__(self, language_config: 'LanguageConfig') -> None:
        ...
    
    def load_yaml(self, filepath: str) -> Dict[str, Any]:
        ...
```

2. **Logging (from utils.py):**
```python
from news_pipeline.utils import log_step_start, log_step_complete

log_step_start("PromptLibrary", "Loading prompt configuration")
# ... load prompts ...
log_step_complete("PromptLibrary", "Prompt configuration loaded")
```

3. **Error Handling (graceful degradation):**
```python
try:
    prompts = self._load_yaml(filepath)
except FileNotFoundError:
    logger.error(f"Prompt file not found: {filepath}")
    # Don't crash - return empty or provide defaults
    prompts = {}
```

4. **Caching Pattern:**
```python
class PromptLibrary:
    def __init__(self, language_config):
        self._cache: Dict[str, Any] = {}
        self._language_config = language_config
    
    def _load_with_cache(self, stage: str) -> Dict:
        if stage not in self._cache:
            filepath = f"config/prompts/{stage}.yaml"
            self._cache[stage] = self._load_yaml(filepath)
        return self._cache[stage]
```

### Class Structure

**Core Classes to Implement:**

1. **PromptLibrary (Main Class):**
   - Manages YAML loading and caching
   - Provides access to pipeline stage subclasses
   - Handles language configuration injection

2. **Pipeline Stage Subclasses:**
   - `FilteringPrompts` - prompts for filter.py
   - `DeduplicationPrompts` - prompts for gpt_deduplication.py, cross_run_deduplication.py
   - `AnalysisPrompts` - prompts for analyzer.py
   - `FormattingPrompts` - prompts for german_rating_formatter.py
   - `DigestPrompts` - prompts for incremental_digest.py, summarizer.py

**Class Relationships:**
```python
class PromptLibrary:
    def __init__(self, language_config: LanguageConfig):
        self.filtering = FilteringPrompts(self, language_config)
        self.deduplication = DeduplicationPrompts(self, language_config)
        self.analysis = AnalysisPrompts(self, language_config)
        self.formatting = FormattingPrompts(self, language_config)
        self.digest = DigestPrompts(self, language_config)

class FilteringPrompts:
    def __init__(self, library: PromptLibrary, language_config: LanguageConfig):
        self._library = library
        self._language_config = language_config
    
    def classification_prompt(self, topic: str) -> str:
        template = self._library.get_prompt("filtering", "classification_prompt")
        return template.format(topic=topic)
```

### Example Implementation Sketch

**Minimal Working Example for Validation:**

```python
# news_pipeline/prompt_library.py
import yaml
from pathlib import Path
from typing import Dict, Any, Optional
import logging

logger = logging.getLogger(__name__)

class PromptLibrary:
    """Central repository for GPT system prompts organized by pipeline stage."""
    
    def __init__(self, language_config: 'LanguageConfig'):
        self._language_config = language_config
        self._cache: Dict[str, Dict[str, Any]] = {}
        self.filtering = FilteringPrompts(self, language_config)
        # ... other stages
    
    def get_prompt(self, stage: str, prompt_name: str) -> str:
        """Retrieve a prompt template from YAML configuration."""
        stage_prompts = self._load_stage_prompts(stage)
        if prompt_name not in stage_prompts:
            raise KeyError(f"Prompt '{prompt_name}' not found in {stage}.yaml")
        return stage_prompts[prompt_name]["template"]
    
    def _load_stage_prompts(self, stage: str) -> Dict[str, Any]:
        """Load and cache prompts for a pipeline stage."""
        if stage not in self._cache:
            filepath = Path("config/prompts") / f"{stage}.yaml"
            with open(filepath, 'r', encoding='utf-8') as f:
                self._cache[stage] = yaml.safe_load(f)
        return self._cache[stage]

class FilteringPrompts:
    """Prompts for the filtering pipeline stage."""
    
    def __init__(self, library: PromptLibrary, language_config: 'LanguageConfig'):
        self._library = library
        self._language_config = language_config
    
    def classification_prompt(self, topic: str) -> str:
        """Get the article classification prompt."""
        template = self._library.get_prompt("filtering", "classification_prompt")
        return template.format(topic=topic)
```

### Testing Strategy

**Source:** docs/architecture.md - Testing Strategy section

**Unit Test Structure:**
```python
# scripts/test_prompt_library.py
import pytest
from news_pipeline.prompt_library import PromptLibrary, FilteringPrompts
from news_pipeline.language_config import LanguageConfig

def test_load_prompt_yaml():
    """Test YAML file loading works correctly."""
    lang_config = LanguageConfig("german")
    prompt_lib = PromptLibrary(lang_config)
    
    # Create minimal test YAML
    # ... setup test file ...
    
    prompt = prompt_lib.get_prompt("filtering", "classification_prompt")
    assert prompt is not None
    assert "{topic}" in prompt

def test_prompt_caching():
    """Test that prompts are cached after first load."""
    lang_config = LanguageConfig("german")
    prompt_lib = PromptLibrary(lang_config)
    
    # First load
    prompt1 = prompt_lib.get_prompt("filtering", "classification_prompt")
    
    # Second load (should use cache)
    prompt2 = prompt_lib.get_prompt("filtering", "classification_prompt")
    
    assert prompt1 == prompt2
    # Could also test that file is only read once

def test_parameter_substitution():
    """Test that parameter substitution works."""
    lang_config = LanguageConfig("german")
    prompt_lib = PromptLibrary(lang_config)
    
    prompt = prompt_lib.filtering.classification_prompt(topic="creditreform")
    assert "creditreform" in prompt
    assert "{topic}" not in prompt  # Template variable replaced

def test_missing_prompt_error():
    """Test error handling for missing prompts."""
    lang_config = LanguageConfig("german")
    prompt_lib = PromptLibrary(lang_config)
    
    with pytest.raises(KeyError):
        prompt_lib.get_prompt("filtering", "nonexistent_prompt")
```

### Dependencies

**From Previous Story:**
- None - this is the first story in Epic 011

**For Next Story:**
- Story 011.2 will use this infrastructure to load actual prompts from YAML files
- Once YAML files exist, this architecture can be fully tested end-to-end

### Risk Mitigation

**Potential Issues:**

1. **YAML Loading Performance:**
   - Mitigated by caching mechanism
   - Load once per stage, reuse for all prompts

2. **Parameter Substitution Complexity:**
   - Start with simple Python string templates (`{variable}`)
   - Avoid complex templating engines (Jinja2) for simplicity

3. **Language Integration:**
   - Follow existing LanguageConfig patterns closely
   - Don't modify LanguageConfig in this story (Story 3 handles that)

### Testing

**Testing Standards:**
**Source:** docs/architecture.md - Testing Strategy section

**Test Framework:** pytest

**Test File Location:** `scripts/test_prompt_library.py`

**Test Coverage Target:** >80% for PromptLibrary core functionality

**Key Tests:**
- YAML loading (valid files)
- Caching mechanism
- Error handling (missing files, missing prompts)
- Parameter substitution
- Language integration
- Each pipeline stage subclass

**Integration with Existing Tests:**
Follow same structure as `scripts/test_gpt_deduplication.py`

### Completion Criteria

**Before Marking Complete:**
- [x] PromptLibrary main class created with YAML loading
- [x] All 5 pipeline stage subclasses implemented
- [x] Caching mechanism works
- [x] Language integration functional
- [x] Example prompt validates end-to-end
- [x] Comprehensive docstrings added
- [x] Unit tests written and passing (20/20 tests pass)
- [x] Code follows PEP 8 and type hint standards
- [x] Change Log updated
- [x] Ready for Story 011.2 (YAML extraction)

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-05 | 1.0 | Initial story draft created from Epic 011 | Scrum Master (Bob) |
| 2025-10-05 | 2.0 | Story implementation completed | Developer (James) |

## Dev Agent Record

### Agent Model Used
Claude 3.5 Sonnet (Cline)

### Debug Log References
None - No debugging required. Implementation proceeded smoothly.

### Completion Notes List
- Successfully created PromptLibrary core architecture with all 5 pipeline stage subclasses
- Implemented YAML loading with efficient caching mechanism
- Language integration via LanguageConfig dependency injection working correctly
- Created example YAML files for validation (example.yaml, filtering.yaml)
- Comprehensive unit tests created: 20 tests, all passing
- TYPE_CHECKING import used to avoid circular dependency issues with LanguageConfig
- Followed existing project patterns (logging, error handling, type hints)
- Architecture validated end-to-end through unit tests
- Ready for Story 011.2 to extract and document actual prompts

### File List
**Created Files:**
- `news_pipeline/prompt_library.py` - Core PromptLibrary implementation (462 lines)
- `config/prompts/example.yaml` - Example YAML for testing
- `config/prompts/filtering.yaml` - Minimal filtering prompts for test validation
- `scripts/test_prompt_library.py` - Comprehensive unit tests (300+ lines)

**Modified Files:**
None - This story only created new files as per acceptance criteria

## QA Results
*This section will be populated by QA Agent after story implementation*
